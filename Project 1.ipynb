{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:25:51.404529Z",
     "start_time": "2018-03-26T19:25:51.263675Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. ratings.dat encapsulating class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:25:52.402929Z",
     "start_time": "2018-03-26T19:25:52.382297Z"
    }
   },
   "outputs": [],
   "source": [
    "class RatingsData(object):\n",
    "    def __init__(self, raw_data_path):\n",
    "        with open(raw_data_path, 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        self._ratings_data = {}\n",
    "\n",
    "        for line in content.split('\\n'):\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            values = line.split('::')\n",
    "            user_ratings = self._ratings_data.get(values[0], {})\n",
    "            user_ratings[values[1]] = float(values[2])\n",
    "            self._ratings_data[values[0]] = user_ratings\n",
    "\n",
    "    def as_matrix(self, movies):\n",
    "\n",
    "        sorted_users = sorted(self._ratings_data.keys())\n",
    "\n",
    "        matrix = []\n",
    "\n",
    "        for user_id in sorted_users:\n",
    "            row = []\n",
    "            for movie in movies:\n",
    "                row.append(self._ratings_data[user_id].get(movie, np.NaN))\n",
    "            matrix.append(row)\n",
    "\n",
    "        return np.array(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. movies.dat encapsulating class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:25:53.766824Z",
     "start_time": "2018-03-26T19:25:53.750108Z"
    }
   },
   "outputs": [],
   "source": [
    "class MoviesData(object):\n",
    "\n",
    "    def __init__(self, raw_data_path):\n",
    "        with open(raw_data_path, 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        self._movies_data = {}\n",
    "\n",
    "        for line in content.split('\\n'):\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            values = line.split('::')\n",
    "            self._movies_data[values[0]] = {\n",
    "                'name': values[1],\n",
    "                'genres': values[2].split('|')\n",
    "            }\n",
    "\n",
    "    def get_available_movies(self):\n",
    "        return sorted(self._movies_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Train-Test split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:25:54.929115Z",
     "start_time": "2018-03-26T19:25:54.909761Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_train_test(ratings_matrix, ratio=0.8):\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for i, user_ratings in enumerate(ratings_matrix):\n",
    "        known_ratings = np.argwhere(~np.isnan(user_ratings)).flatten()\n",
    "        train_ratings = np.random.choice(known_ratings, int(len(known_ratings) * ratio), replace=False)\n",
    "        test_ratings = np.setdiff1d(known_ratings, train_ratings)\n",
    "\n",
    "        row = user_ratings.copy()\n",
    "        mask = np.ones(row.shape, dtype=bool)\n",
    "        mask[train_ratings] = False\n",
    "        row[mask] = np.NaN\n",
    "        train.append(row)\n",
    "  \n",
    "        row = user_ratings.copy()\n",
    "        mask = np.ones(row.shape, dtype=bool)\n",
    "        mask[test_ratings] = False\n",
    "        row[mask] = np.NaN\n",
    "        test.append(row)\n",
    "\n",
    "    return np.vstack(train), np.vstack(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Required **hyper**parameters:  \n",
    "  * $k$ - Dimensionality factor\n",
    "  * $\\lambda_u$ - Users rows regularization factor\n",
    "  * $\\lambda_v$ - Movies rows regularization factor\n",
    "  * $\\lambda_{b_u}$ - Users rows bias regularization factor\n",
    "  * $\\lambda_{b_v}$ - Movies rows bias regularization factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:25:56.827118Z",
     "start_time": "2018-03-26T19:25:56.821948Z"
    }
   },
   "outputs": [],
   "source": [
    "class Hyperparameters(object):\n",
    "\n",
    "    def __init__(self, dim, reg_users=1e-3, reg_items=1e-3, reg_bias_users=1e-3, reg_bias_items=1e-3):\n",
    "        self.k = dim\n",
    "        self.lambda_u = reg_users\n",
    "        self.lambda_v = reg_items\n",
    "        self.lambda_bu = reg_bias_users\n",
    "        self.lambda_bv = reg_bias_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Model parameters encapsulating class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:25:57.403936Z",
     "start_time": "2018-03-26T19:25:57.397427Z"
    }
   },
   "outputs": [],
   "source": [
    "class MFModel(object):\n",
    "\n",
    "    def __init__(self, hyperparams, num_of_users, num_of_movies):\n",
    "        self.hyper = hyperparams\n",
    "        self.U = np.random.randn(hyperparams.k, num_of_users)\n",
    "        self.V = np.random.randn(hyperparams.k, num_of_movies)\n",
    "        self.Ub = np.random.randn(num_of_users, 1)\n",
    "        self.Vb = np.random.randn(num_of_movies, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1.\n",
    "$$ \\frac{\\partial E}{\\partial U_m} = \n",
    "\\sum_{n \\in I_m} -\\left ( r_{m,n} - \\left (U_m^TV_n + b_n + b_m \\right ) \\right ) V_n + \\lambda_UU_m$$\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial V_n} = \n",
    "\\sum_{m \\in I_n} -\\left ( r_{m,n} - \\left (U_m^TV_n + b_n + b_m \\right ) \\right ) U_m + \\lambda_VV_n$$\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial b_m} = \n",
    "\\sum_{n \\in I_m} -\\left ( r_{m,n} - \\left (U_m^TV_n + b_n + b_m \\right ) \\right ) + \\lambda_{b_u}b_m$$\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial b_n} = \n",
    "\\sum_{m \\in I_m} -\\left ( r_{m,n} - \\left (U_m^TV_n + b_n + b_m \\right ) \\right ) + \\lambda_{b_v}b_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Stochastic Gradient Descent\n",
    "       (a) Update equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:26:01.214092Z",
     "start_time": "2018-03-26T19:26:01.165541Z"
    }
   },
   "outputs": [],
   "source": [
    "def derive_by_um(R, U, V, Ub, Vb, lambda_u, m):\n",
    "    predict = np.vectorize(lambda n: np.dot(U.T[m], V[:, n]) + Vb[n] + Ub[m])\n",
    "    ns = np.argwhere(~np.isnan(R[m])).reshape(-1)\n",
    "    error = (R[m, ns] - predict(ns)).reshape(-1, 1) * -V[:, ns].T\n",
    "\n",
    "    return error.sum(axis=0) + lambda_u * U[:, m]\n",
    "\n",
    "\n",
    "def derive_by_vn(R, U, V, Ub, Vb, lambda_v, n):\n",
    "    predict = np.vectorize(lambda m: np.dot(U.T[m], V[:, n]) + Vb[n] + Ub[m])\n",
    "    ms = np.argwhere(~np.isnan(R[:, n])).reshape(-1)\n",
    "    error = (R[ms, n] - predict(ms)).reshape(-1, 1) * -U[:, ms].T\n",
    "\n",
    "    return error.sum(axis=0).reshape(-1) + lambda_v * V[:, n]\n",
    "\n",
    "\n",
    "def derive_by_bm(R, U, V, Ub, Vb, lambda_bu, m):\n",
    "    predict = np.vectorize(lambda n: np.dot(U.T[m], V[:, n]) + Vb[n] + Ub[m])\n",
    "    ns = np.argwhere(~np.isnan(R[m]))\n",
    "    error = -(R[m, ns] - predict(ns))\n",
    "\n",
    "    return error.sum() + lambda_bu * Ub[m]\n",
    "\n",
    "\n",
    "def derive_by_bn(R, U, V, Ub, Vb, lambda_bv, n):\n",
    "    predict = np.vectorize(lambda m: np.dot(U.T[m], V[:, n]) + Vb[n] + Ub[m])\n",
    "    ms = np.argwhere(~np.isnan(R[:, n]))\n",
    "    error = -(R[ms, n] - predict(ms))\n",
    "\n",
    "    return error.sum() + lambda_bv * Vb[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        (b) SGD parameters encapsulating class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T20:35:49.181649Z",
     "start_time": "2018-03-26T20:35:49.176065Z"
    }
   },
   "outputs": [],
   "source": [
    "class SGDParameters(object):\n",
    "    \n",
    "    def __init__(self, step_size=1e-4, epocs=50):\n",
    "        self.alpha = step_size\n",
    "        self.epocs = epocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        (c) LearnModelFromDataUsingSGD implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:26:04.010348Z",
     "start_time": "2018-03-26T19:26:03.996977Z"
    }
   },
   "outputs": [],
   "source": [
    "def LearnModelFromDataUsingSGD(dataset, model_params, algorithm_params):\n",
    "    U, V, Ub, Vb = model_params.U, model_params.V, model_params.Ub, model_params.Vb\n",
    "\n",
    "    for epoc in range(algorithm_params.epocs):\n",
    "        print 'Epoch: ', epoc\n",
    "        print 'RMSE: ', RMSE(U, V, Ub, Vb, dataset)\n",
    "\n",
    "        for m, n in np.argwhere(~np.isnan(dataset)):\n",
    "\n",
    "            U[:, m] -= algorithm_params.alpha * derive_by_um(dataset, U, V, Ub, Vb, model_params.hyper.lambda_u, m)\n",
    "            V[:, n] -= algorithm_params.alpha * derive_by_vn(dataset, U, V, Ub, Vb, model_params.hyper.lambda_v, n)\n",
    "            Ub[m] -= algorithm_params.alpha * derive_by_bm(dataset, U, V, Ub, Vb, model_params.hyper.lambda_bu, m)\n",
    "            Vb[n] -= algorithm_params.alpha * derive_by_bn(dataset, U, V, Ub, Vb, model_params.hyper.lambda_bv, n)\n",
    "\n",
    "    return U, V, Ub, Vb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T20:35:02.410025Z",
     "start_time": "2018-03-26T20:34:55.714007Z"
    }
   },
   "outputs": [],
   "source": [
    "movies = MoviesData('movies.dat')\n",
    "ratings = RatingsData('ratings.dat')\n",
    "\n",
    "full_dataset = ratings.as_matrix(movies.get_available_movies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T17:14:51.088970Z",
     "start_time": "2018-03-26T17:14:51.069973Z"
    }
   },
   "outputs": [],
   "source": [
    "reduced_dataset = full_dataset[:1000, :500]\n",
    "mask = ~np.isnan(reduced_dataset)\n",
    "reduced_dataset = reduced_dataset[mask.sum(axis=1) > 0]\n",
    "mask = ~np.isnan(reduced_dataset)\n",
    "reduced_dataset = reduced_dataset[:, mask.sum(axis=0) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T20:35:53.226885Z",
     "start_time": "2018-03-26T20:35:52.191575Z"
    }
   },
   "outputs": [],
   "source": [
    "model_params = MFModel(Hyperparameters(100), *full_dataset.shape)\n",
    "algorithm_params = SGDParameters(epocs=50)\n",
    "\n",
    "train_set, test_set = split_train_test(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T19:27:48.695077Z",
     "start_time": "2018-03-26T19:27:48.682633Z"
    }
   },
   "outputs": [],
   "source": [
    "def RMSE(U, V, Ub, Vb, dataset):\n",
    "    pred = np.dot(U.T, V) + Ub.reshape(-1, 1) + Vb.reshape(-1, 1).T\n",
    "    mask = ~np.isnan(dataset)\n",
    "    return np.sqrt(np.power(pred[mask] - dataset[mask], 2).sum() / mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T15:31:59.810585Z",
     "start_time": "2018-03-26T20:35:56.270247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "RMSE:  10.765480402483208\n",
      "Epoch:  1\n",
      "RMSE:  1.159431987821029\n",
      "Epoch:  2\n",
      "RMSE:  0.8842700740014439\n",
      "Epoch:  3\n",
      "RMSE:  0.811985251105999\n",
      "Epoch:  4\n",
      "RMSE:  0.7781430688356192\n",
      "Epoch:  5\n",
      "RMSE:  0.7573423744701497\n",
      "Epoch:  6\n",
      "RMSE:  0.7423098307474274\n",
      "Epoch:  7\n",
      "RMSE:  0.7303459008883584\n",
      "Epoch:  8\n",
      "RMSE:  0.7202509059807491\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-49a06fa4d4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearnModelFromDataUsingSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-fb9551b6569a>\u001b[0m in \u001b[0;36mLearnModelFromDataUsingSGD\u001b[0;34m(dataset, model_params, algorithm_params)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malgorithm_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mderive_by_um\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malgorithm_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mderive_by_vn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mUb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malgorithm_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mderive_by_bm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_bu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mVb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malgorithm_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mderive_by_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_bv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-854306515591>\u001b[0m in \u001b[0;36mderive_by_vn\u001b[0;34m(R, U, V, Ub, Vb, lambda_v, n)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mVb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mUb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_v\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = LearnModelFromDataUsingSGD(train_set, model_params, algorithm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "305px",
    "left": "1213px",
    "right": "20px",
    "top": "154px",
    "width": "601px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
